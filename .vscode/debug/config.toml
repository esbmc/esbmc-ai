ai_model = "openai:gpt-5-nano"
temp_auto_clean = true
#temp_file_dir = "temp"
allow_successful = false
loading_hints = false
source_code_format = "full"
dev_mode = true

[ai_custom."llama3.2:3b"]
server_type = "ollama"
url = "localhost:11434"
max_tokens = 100000

[ai_custom."llama3.3:latest"]
server_type = "ollama"
url = "localhost:11435"
max_tokens = 100000

[solution]
filenames = ["samples/threading.c"]

[verifier]
name = "esbmc"

[verifier.esbmc]
path = "~/.local/bin/esbmc"
params = [
    "--interval-analysis",
    "--memory-leak-check",
    "--goto-unwind",
    "--unlimited-goto-unwind",
    "--k-induction",
    "--state-hashing",
    "--add-symex-value-sets",
    "--k-step",
    "2",
    "--floatbv",
    "--unlimited-k-steps",
    "--context-bound",
    "2",
]
output_type = "full"
timeout = 60

[llm_requests]
max_tries = 5
timeout = 60
